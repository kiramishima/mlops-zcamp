{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module.\n",
    "\n",
    "\n",
    "## Q1. Downloading the data\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page),\n",
    "but instead of \"**Green** Taxi Trip Records\", we'll use \"**Yellow** Taxi Trip Records\".\n",
    "\n",
    "Download the data for January and February 2023.\n",
    "\n",
    "Read the data for January. How many columns are there?\n",
    "\n",
    "* 16\n",
    "* 17\n",
    "* 18\n",
    "* 19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadYellowTripData(year, month_start, month_end):\n",
    "    data = []\n",
    "    for m in range(month_start, month_end+1):\n",
    "        url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{m:02d}.parquet\"\n",
    "        print(f\"Processing yellow_tripdata_{year}-{m:02d}.parquet\")\n",
    "        df = pd.read_parquet(url)\n",
    "        df['month'] = f\"{m:02d}\"\n",
    "        data.append(df)\n",
    "    return pd.concat(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\"\n",
    "df = pd.read_parquet(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3066766, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3066766 entries, 0 to 3066765\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int64         \n",
      " 1   tpep_pickup_datetime   datetime64[us]\n",
      " 2   tpep_dropoff_datetime  datetime64[us]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           int64         \n",
      " 8   DOLocationID           int64         \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  airport_fee            float64       \n",
      "dtypes: datetime64[us](2), float64(12), int64(4), object(1)\n",
      "memory usage: 444.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing yellow_tripdata_2023-01.parquet\n",
      "Processing yellow_tripdata_2023-02.parquet\n"
     ]
    }
   ],
   "source": [
    "dfAll = loadYellowTripData(2023, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5980721 entries, 0 to 5980720\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int64         \n",
      " 1   tpep_pickup_datetime   datetime64[us]\n",
      " 2   tpep_dropoff_datetime  datetime64[us]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           int64         \n",
      " 8   DOLocationID           int64         \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  airport_fee            float64       \n",
      " 19  month                  object        \n",
      " 20  Airport_fee            float64       \n",
      "dtypes: datetime64[us](2), float64(13), int64(4), object(2)\n",
      "memory usage: 958.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dfAll.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3066766, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAll[dfAll.month == '01'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Computing duration\n",
    "\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes. \n",
    "\n",
    "What's the standard deviation of the trips duration in January?\n",
    "\n",
    "* 32.59\n",
    "* 42.59\n",
    "* 52.59\n",
    "* 62.59\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# January\n",
    "df_jan = dfAll[dfAll.month == '01']\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiramishima\\AppData\\Local\\Temp\\ipykernel_36632\\3925291819.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_jan['duration'] = df_jan.tpep_dropoff_datetime - df_jan.tpep_pickup_datetime\n"
     ]
    }
   ],
   "source": [
    "df_jan['duration'] = df_jan.tpep_dropoff_datetime - df_jan.tpep_pickup_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>...</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>month</th>\n",
       "      <th>Airport_fee</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:32:10</td>\n",
       "      <td>2023-01-01 00:40:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:08:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:55:08</td>\n",
       "      <td>2023-01-01 01:01:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:06:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:25:04</td>\n",
       "      <td>2023-01-01 00:37:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:12:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01 00:03:48</td>\n",
       "      <td>2023-01-01 00:13:25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:09:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:10:29</td>\n",
       "      <td>2023-01-01 00:21:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:10:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
       "1         2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
       "2         2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
       "3         1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
       "4         2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           0.97         1.0                  N           161           141   \n",
       "1           1.10         1.0                  N            43           237   \n",
       "2           2.51         1.0                  N            48           238   \n",
       "3           1.90         1.0                  N           138             7   \n",
       "4           1.43         1.0                  N           107            79   \n",
       "\n",
       "   payment_type  ...  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2  ...      0.5        0.00           0.0   \n",
       "1             1  ...      0.5        4.00           0.0   \n",
       "2             1  ...      0.5       15.00           0.0   \n",
       "3             1  ...      0.5        0.00           0.0   \n",
       "4             1  ...      0.5        3.28           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \\\n",
       "0                    1.0         14.30                   2.5         0.00   \n",
       "1                    1.0         16.90                   2.5         0.00   \n",
       "2                    1.0         34.90                   2.5         0.00   \n",
       "3                    1.0         20.85                   0.0         1.25   \n",
       "4                    1.0         19.68                   2.5         0.00   \n",
       "\n",
       "   month  Airport_fee        duration  \n",
       "0     01          NaN 0 days 00:08:26  \n",
       "1     01          NaN 0 days 00:06:19  \n",
       "2     01          NaN 0 days 00:12:45  \n",
       "3     01          NaN 0 days 00:09:37  \n",
       "4     01          NaN 0 days 00:10:50  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = df_jan.duration.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.433333333333334"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiramishima\\AppData\\Local\\Temp\\ipykernel_36632\\725587808.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_jan.duration = df_jan.duration.apply(lambda td: td.total_seconds() / 60)\n"
     ]
    }
   ],
   "source": [
    "df_jan.duration = df_jan.duration.apply(lambda td: td.total_seconds() / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>...</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>month</th>\n",
       "      <th>Airport_fee</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:32:10</td>\n",
       "      <td>2023-01-01 00:40:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:55:08</td>\n",
       "      <td>2023-01-01 01:01:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:25:04</td>\n",
       "      <td>2023-01-01 00:37:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01 00:03:48</td>\n",
       "      <td>2023-01-01 00:13:25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:10:29</td>\n",
       "      <td>2023-01-01 00:21:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
       "1         2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
       "2         2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
       "3         1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
       "4         2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           0.97         1.0                  N           161           141   \n",
       "1           1.10         1.0                  N            43           237   \n",
       "2           2.51         1.0                  N            48           238   \n",
       "3           1.90         1.0                  N           138             7   \n",
       "4           1.43         1.0                  N           107            79   \n",
       "\n",
       "   payment_type  ...  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2  ...      0.5        0.00           0.0   \n",
       "1             1  ...      0.5        4.00           0.0   \n",
       "2             1  ...      0.5       15.00           0.0   \n",
       "3             1  ...      0.5        0.00           0.0   \n",
       "4             1  ...      0.5        3.28           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \\\n",
       "0                    1.0         14.30                   2.5         0.00   \n",
       "1                    1.0         16.90                   2.5         0.00   \n",
       "2                    1.0         34.90                   2.5         0.00   \n",
       "3                    1.0         20.85                   0.0         1.25   \n",
       "4                    1.0         19.68                   2.5         0.00   \n",
       "\n",
       "   month  Airport_fee   duration  \n",
       "0     01          NaN   8.433333  \n",
       "1     01          NaN   6.316667  \n",
       "2     01          NaN  12.750000  \n",
       "3     01          NaN   9.616667  \n",
       "4     01          NaN  10.833333  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.066766e+06\n",
       "mean     1.566900e+01\n",
       "std      4.259435e+01\n",
       "min     -2.920000e+01\n",
       "25%      7.116667e+00\n",
       "50%      1.151667e+01\n",
       "75%      1.830000e+01\n",
       "max      1.002918e+04\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jan.duration.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.59"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jan.duration.std().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Dropping outliers\n",
    "\n",
    "Next, we need to check the distribution of the `duration` variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "* 90%\n",
    "* 92%\n",
    "* 95%\n",
    "* 98%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_jan[(df_jan.duration > 1) & (df_jan.duration < 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.008849e+06\n",
       "mean     1.420544e+01\n",
       "std      9.937594e+00\n",
       "min      1.016667e+00\n",
       "25%      7.216667e+00\n",
       "50%      1.155000e+01\n",
       "75%      1.818333e+01\n",
       "max      5.998333e+01\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.duration.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(len(df1) / len(df_jan) * 100, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model. \n",
    "\n",
    "* Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will \n",
    "  label encode them)\n",
    "* Fit a dictionary vectorizer \n",
    "* Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "* 2\n",
    "* 155\n",
    "* 345\n",
    "* 515\n",
    "* 715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "target = ['duration']\n",
    "del df_jan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma listas de diccionarios de valores-características en vectores\n",
    "dv = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains_dicts = df1[categorical].astype(str).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dv.fit_transform(trains_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3008849x515 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6017698 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DOLocationID=1', 'DOLocationID=10', 'DOLocationID=100',\n",
       "       'DOLocationID=101', 'DOLocationID=102', 'DOLocationID=106',\n",
       "       'DOLocationID=107', 'DOLocationID=108', 'DOLocationID=109',\n",
       "       'DOLocationID=11', 'DOLocationID=111', 'DOLocationID=112',\n",
       "       'DOLocationID=113', 'DOLocationID=114', 'DOLocationID=115',\n",
       "       'DOLocationID=116', 'DOLocationID=117', 'DOLocationID=118',\n",
       "       'DOLocationID=119', 'DOLocationID=12', 'DOLocationID=120',\n",
       "       'DOLocationID=121', 'DOLocationID=122', 'DOLocationID=123',\n",
       "       'DOLocationID=124', 'DOLocationID=125', 'DOLocationID=126',\n",
       "       'DOLocationID=127', 'DOLocationID=128', 'DOLocationID=129',\n",
       "       'DOLocationID=13', 'DOLocationID=130', 'DOLocationID=131',\n",
       "       'DOLocationID=132', 'DOLocationID=133', 'DOLocationID=134',\n",
       "       'DOLocationID=135', 'DOLocationID=136', 'DOLocationID=137',\n",
       "       'DOLocationID=138', 'DOLocationID=139', 'DOLocationID=14',\n",
       "       'DOLocationID=140', 'DOLocationID=141', 'DOLocationID=142',\n",
       "       'DOLocationID=143', 'DOLocationID=144', 'DOLocationID=145',\n",
       "       'DOLocationID=146', 'DOLocationID=147', 'DOLocationID=148',\n",
       "       'DOLocationID=149', 'DOLocationID=15', 'DOLocationID=150',\n",
       "       'DOLocationID=151', 'DOLocationID=152', 'DOLocationID=153',\n",
       "       'DOLocationID=154', 'DOLocationID=155', 'DOLocationID=156',\n",
       "       'DOLocationID=157', 'DOLocationID=158', 'DOLocationID=159',\n",
       "       'DOLocationID=16', 'DOLocationID=160', 'DOLocationID=161',\n",
       "       'DOLocationID=162', 'DOLocationID=163', 'DOLocationID=164',\n",
       "       'DOLocationID=165', 'DOLocationID=166', 'DOLocationID=167',\n",
       "       'DOLocationID=168', 'DOLocationID=169', 'DOLocationID=17',\n",
       "       'DOLocationID=170', 'DOLocationID=171', 'DOLocationID=172',\n",
       "       'DOLocationID=173', 'DOLocationID=174', 'DOLocationID=175',\n",
       "       'DOLocationID=176', 'DOLocationID=177', 'DOLocationID=178',\n",
       "       'DOLocationID=179', 'DOLocationID=18', 'DOLocationID=180',\n",
       "       'DOLocationID=181', 'DOLocationID=182', 'DOLocationID=183',\n",
       "       'DOLocationID=184', 'DOLocationID=185', 'DOLocationID=186',\n",
       "       'DOLocationID=187', 'DOLocationID=188', 'DOLocationID=189',\n",
       "       'DOLocationID=19', 'DOLocationID=190', 'DOLocationID=191',\n",
       "       'DOLocationID=192', 'DOLocationID=193', 'DOLocationID=194',\n",
       "       'DOLocationID=195', 'DOLocationID=196', 'DOLocationID=197',\n",
       "       'DOLocationID=198', 'DOLocationID=2', 'DOLocationID=20',\n",
       "       'DOLocationID=200', 'DOLocationID=201', 'DOLocationID=202',\n",
       "       'DOLocationID=203', 'DOLocationID=204', 'DOLocationID=205',\n",
       "       'DOLocationID=206', 'DOLocationID=207', 'DOLocationID=208',\n",
       "       'DOLocationID=209', 'DOLocationID=21', 'DOLocationID=210',\n",
       "       'DOLocationID=211', 'DOLocationID=212', 'DOLocationID=213',\n",
       "       'DOLocationID=214', 'DOLocationID=215', 'DOLocationID=216',\n",
       "       'DOLocationID=217', 'DOLocationID=218', 'DOLocationID=219',\n",
       "       'DOLocationID=22', 'DOLocationID=220', 'DOLocationID=221',\n",
       "       'DOLocationID=222', 'DOLocationID=223', 'DOLocationID=224',\n",
       "       'DOLocationID=225', 'DOLocationID=226', 'DOLocationID=227',\n",
       "       'DOLocationID=228', 'DOLocationID=229', 'DOLocationID=23',\n",
       "       'DOLocationID=230', 'DOLocationID=231', 'DOLocationID=232',\n",
       "       'DOLocationID=233', 'DOLocationID=234', 'DOLocationID=235',\n",
       "       'DOLocationID=236', 'DOLocationID=237', 'DOLocationID=238',\n",
       "       'DOLocationID=239', 'DOLocationID=24', 'DOLocationID=240',\n",
       "       'DOLocationID=241', 'DOLocationID=242', 'DOLocationID=243',\n",
       "       'DOLocationID=244', 'DOLocationID=245', 'DOLocationID=246',\n",
       "       'DOLocationID=247', 'DOLocationID=248', 'DOLocationID=249',\n",
       "       'DOLocationID=25', 'DOLocationID=250', 'DOLocationID=251',\n",
       "       'DOLocationID=252', 'DOLocationID=253', 'DOLocationID=254',\n",
       "       'DOLocationID=255', 'DOLocationID=256', 'DOLocationID=257',\n",
       "       'DOLocationID=258', 'DOLocationID=259', 'DOLocationID=26',\n",
       "       'DOLocationID=260', 'DOLocationID=261', 'DOLocationID=262',\n",
       "       'DOLocationID=263', 'DOLocationID=264', 'DOLocationID=265',\n",
       "       'DOLocationID=27', 'DOLocationID=28', 'DOLocationID=29',\n",
       "       'DOLocationID=3', 'DOLocationID=30', 'DOLocationID=31',\n",
       "       'DOLocationID=32', 'DOLocationID=33', 'DOLocationID=34',\n",
       "       'DOLocationID=35', 'DOLocationID=36', 'DOLocationID=37',\n",
       "       'DOLocationID=38', 'DOLocationID=39', 'DOLocationID=4',\n",
       "       'DOLocationID=40', 'DOLocationID=41', 'DOLocationID=42',\n",
       "       'DOLocationID=43', 'DOLocationID=44', 'DOLocationID=45',\n",
       "       'DOLocationID=46', 'DOLocationID=47', 'DOLocationID=48',\n",
       "       'DOLocationID=49', 'DOLocationID=5', 'DOLocationID=50',\n",
       "       'DOLocationID=51', 'DOLocationID=52', 'DOLocationID=53',\n",
       "       'DOLocationID=54', 'DOLocationID=55', 'DOLocationID=56',\n",
       "       'DOLocationID=57', 'DOLocationID=58', 'DOLocationID=59',\n",
       "       'DOLocationID=6', 'DOLocationID=60', 'DOLocationID=61',\n",
       "       'DOLocationID=62', 'DOLocationID=63', 'DOLocationID=64',\n",
       "       'DOLocationID=65', 'DOLocationID=66', 'DOLocationID=67',\n",
       "       'DOLocationID=68', 'DOLocationID=69', 'DOLocationID=7',\n",
       "       'DOLocationID=70', 'DOLocationID=71', 'DOLocationID=72',\n",
       "       'DOLocationID=73', 'DOLocationID=74', 'DOLocationID=75',\n",
       "       'DOLocationID=76', 'DOLocationID=77', 'DOLocationID=78',\n",
       "       'DOLocationID=79', 'DOLocationID=8', 'DOLocationID=80',\n",
       "       'DOLocationID=81', 'DOLocationID=82', 'DOLocationID=83',\n",
       "       'DOLocationID=84', 'DOLocationID=85', 'DOLocationID=86',\n",
       "       'DOLocationID=87', 'DOLocationID=88', 'DOLocationID=89',\n",
       "       'DOLocationID=9', 'DOLocationID=90', 'DOLocationID=91',\n",
       "       'DOLocationID=92', 'DOLocationID=93', 'DOLocationID=94',\n",
       "       'DOLocationID=95', 'DOLocationID=96', 'DOLocationID=97',\n",
       "       'DOLocationID=98', 'DOLocationID=99', 'PULocationID=1',\n",
       "       'PULocationID=10', 'PULocationID=100', 'PULocationID=101',\n",
       "       'PULocationID=102', 'PULocationID=106', 'PULocationID=107',\n",
       "       'PULocationID=108', 'PULocationID=109', 'PULocationID=11',\n",
       "       'PULocationID=111', 'PULocationID=112', 'PULocationID=113',\n",
       "       'PULocationID=114', 'PULocationID=115', 'PULocationID=116',\n",
       "       'PULocationID=117', 'PULocationID=118', 'PULocationID=119',\n",
       "       'PULocationID=12', 'PULocationID=120', 'PULocationID=121',\n",
       "       'PULocationID=122', 'PULocationID=123', 'PULocationID=124',\n",
       "       'PULocationID=125', 'PULocationID=126', 'PULocationID=127',\n",
       "       'PULocationID=128', 'PULocationID=129', 'PULocationID=13',\n",
       "       'PULocationID=130', 'PULocationID=131', 'PULocationID=132',\n",
       "       'PULocationID=133', 'PULocationID=134', 'PULocationID=135',\n",
       "       'PULocationID=136', 'PULocationID=137', 'PULocationID=138',\n",
       "       'PULocationID=139', 'PULocationID=14', 'PULocationID=140',\n",
       "       'PULocationID=141', 'PULocationID=142', 'PULocationID=143',\n",
       "       'PULocationID=144', 'PULocationID=145', 'PULocationID=146',\n",
       "       'PULocationID=147', 'PULocationID=148', 'PULocationID=149',\n",
       "       'PULocationID=15', 'PULocationID=150', 'PULocationID=151',\n",
       "       'PULocationID=152', 'PULocationID=153', 'PULocationID=154',\n",
       "       'PULocationID=155', 'PULocationID=156', 'PULocationID=157',\n",
       "       'PULocationID=158', 'PULocationID=159', 'PULocationID=16',\n",
       "       'PULocationID=160', 'PULocationID=161', 'PULocationID=162',\n",
       "       'PULocationID=163', 'PULocationID=164', 'PULocationID=165',\n",
       "       'PULocationID=166', 'PULocationID=167', 'PULocationID=168',\n",
       "       'PULocationID=169', 'PULocationID=17', 'PULocationID=170',\n",
       "       'PULocationID=171', 'PULocationID=172', 'PULocationID=173',\n",
       "       'PULocationID=174', 'PULocationID=175', 'PULocationID=177',\n",
       "       'PULocationID=178', 'PULocationID=179', 'PULocationID=18',\n",
       "       'PULocationID=180', 'PULocationID=181', 'PULocationID=182',\n",
       "       'PULocationID=183', 'PULocationID=184', 'PULocationID=185',\n",
       "       'PULocationID=186', 'PULocationID=187', 'PULocationID=188',\n",
       "       'PULocationID=189', 'PULocationID=19', 'PULocationID=190',\n",
       "       'PULocationID=191', 'PULocationID=192', 'PULocationID=193',\n",
       "       'PULocationID=194', 'PULocationID=195', 'PULocationID=196',\n",
       "       'PULocationID=197', 'PULocationID=198', 'PULocationID=199',\n",
       "       'PULocationID=2', 'PULocationID=20', 'PULocationID=200',\n",
       "       'PULocationID=201', 'PULocationID=202', 'PULocationID=203',\n",
       "       'PULocationID=205', 'PULocationID=206', 'PULocationID=207',\n",
       "       'PULocationID=208', 'PULocationID=209', 'PULocationID=21',\n",
       "       'PULocationID=210', 'PULocationID=211', 'PULocationID=212',\n",
       "       'PULocationID=213', 'PULocationID=214', 'PULocationID=215',\n",
       "       'PULocationID=216', 'PULocationID=217', 'PULocationID=218',\n",
       "       'PULocationID=219', 'PULocationID=22', 'PULocationID=220',\n",
       "       'PULocationID=221', 'PULocationID=222', 'PULocationID=223',\n",
       "       'PULocationID=224', 'PULocationID=225', 'PULocationID=226',\n",
       "       'PULocationID=227', 'PULocationID=228', 'PULocationID=229',\n",
       "       'PULocationID=23', 'PULocationID=230', 'PULocationID=231',\n",
       "       'PULocationID=232', 'PULocationID=233', 'PULocationID=234',\n",
       "       'PULocationID=235', 'PULocationID=236', 'PULocationID=237',\n",
       "       'PULocationID=238', 'PULocationID=239', 'PULocationID=24',\n",
       "       'PULocationID=240', 'PULocationID=241', 'PULocationID=242',\n",
       "       'PULocationID=243', 'PULocationID=244', 'PULocationID=245',\n",
       "       'PULocationID=246', 'PULocationID=247', 'PULocationID=248',\n",
       "       'PULocationID=249', 'PULocationID=25', 'PULocationID=250',\n",
       "       'PULocationID=251', 'PULocationID=252', 'PULocationID=253',\n",
       "       'PULocationID=254', 'PULocationID=255', 'PULocationID=256',\n",
       "       'PULocationID=257', 'PULocationID=258', 'PULocationID=259',\n",
       "       'PULocationID=26', 'PULocationID=260', 'PULocationID=261',\n",
       "       'PULocationID=262', 'PULocationID=263', 'PULocationID=264',\n",
       "       'PULocationID=265', 'PULocationID=28', 'PULocationID=29',\n",
       "       'PULocationID=3', 'PULocationID=30', 'PULocationID=31',\n",
       "       'PULocationID=32', 'PULocationID=33', 'PULocationID=34',\n",
       "       'PULocationID=35', 'PULocationID=36', 'PULocationID=37',\n",
       "       'PULocationID=38', 'PULocationID=39', 'PULocationID=4',\n",
       "       'PULocationID=40', 'PULocationID=41', 'PULocationID=42',\n",
       "       'PULocationID=43', 'PULocationID=44', 'PULocationID=45',\n",
       "       'PULocationID=46', 'PULocationID=47', 'PULocationID=48',\n",
       "       'PULocationID=49', 'PULocationID=5', 'PULocationID=50',\n",
       "       'PULocationID=51', 'PULocationID=52', 'PULocationID=53',\n",
       "       'PULocationID=54', 'PULocationID=55', 'PULocationID=56',\n",
       "       'PULocationID=57', 'PULocationID=58', 'PULocationID=6',\n",
       "       'PULocationID=60', 'PULocationID=61', 'PULocationID=62',\n",
       "       'PULocationID=63', 'PULocationID=64', 'PULocationID=65',\n",
       "       'PULocationID=66', 'PULocationID=67', 'PULocationID=68',\n",
       "       'PULocationID=69', 'PULocationID=7', 'PULocationID=70',\n",
       "       'PULocationID=71', 'PULocationID=72', 'PULocationID=73',\n",
       "       'PULocationID=74', 'PULocationID=75', 'PULocationID=76',\n",
       "       'PULocationID=77', 'PULocationID=78', 'PULocationID=79',\n",
       "       'PULocationID=8', 'PULocationID=80', 'PULocationID=81',\n",
       "       'PULocationID=82', 'PULocationID=83', 'PULocationID=85',\n",
       "       'PULocationID=86', 'PULocationID=87', 'PULocationID=88',\n",
       "       'PULocationID=89', 'PULocationID=9', 'PULocationID=90',\n",
       "       'PULocationID=91', 'PULocationID=92', 'PULocationID=93',\n",
       "       'PULocationID=94', 'PULocationID=95', 'PULocationID=96',\n",
       "       'PULocationID=97', 'PULocationID=98'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compactamos\n",
    "X_train = csr_matrix(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3008849, 515)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del dv\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model. \n",
    "\n",
    "* Train a plain linear regression model with default parameters \n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "* 3.64\n",
    "* 7.64\n",
    "* 11.64\n",
    "* 16.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df1[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yellow_trip_model.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardando el modelo\n",
    "joblib.dump(lr, 'yellow_trip_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir Y2\n",
    "Y2 = lr.predict(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular RMSE\n",
    "rmse = np.sqrt(mean_squared_error(Y, Y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.648"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(rmse, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2023). \n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "* 3.81\n",
    "* 7.81\n",
    "* 11.81\n",
    "* 16.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "    df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "\n",
    "    df['duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "    return df[(df.duration > 1) & (df.duration < 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_features_ohe(df, categorical=[]):\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    trains_dicts = df[categorical].astype(str).to_dict(orient='records')\n",
    "    X_train = dv.fit_transform(trains_dicts)\n",
    "    X_train = X_train.astype(np.float32)\n",
    "\n",
    "    pad_zero = np.zeros((X_train.shape[0], 1))\n",
    "    X_train = np.hstack([X_train, pad_zero])\n",
    "    return csr_matrix(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-01 00:32:53</td>\n",
       "      <td>2023-02-01 00:34:34</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>4.40</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-01 00:35:16</td>\n",
       "      <td>2023-02-01 00:35:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-5.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-01 00:35:16</td>\n",
       "      <td>2023-02-01 00:35:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-01 00:29:33</td>\n",
       "      <td>2023-02-01 01:01:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>70.90</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-01 00:12:28</td>\n",
       "      <td>2023-02-01 00:25:46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913950</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-28 23:46:00</td>\n",
       "      <td>2023-03-01 00:05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>249</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>20.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913951</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-28 23:26:02</td>\n",
       "      <td>2023-02-28 23:37:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>186</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913952</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-28 23:24:00</td>\n",
       "      <td>2023-02-28 23:38:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>158</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>17.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913953</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-28 23:03:00</td>\n",
       "      <td>2023-02-28 23:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>79</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>13.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913954</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-28 23:03:03</td>\n",
       "      <td>2023-02-28 23:12:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>161</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>14.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2913955 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0               1  2023-02-01 00:32:53   2023-02-01 00:34:34              2.0   \n",
       "1               2  2023-02-01 00:35:16   2023-02-01 00:35:30              1.0   \n",
       "2               2  2023-02-01 00:35:16   2023-02-01 00:35:30              1.0   \n",
       "3               1  2023-02-01 00:29:33   2023-02-01 01:01:38              0.0   \n",
       "4               2  2023-02-01 00:12:28   2023-02-01 00:25:46              1.0   \n",
       "...           ...                  ...                   ...              ...   \n",
       "2913950         2  2023-02-28 23:46:00   2023-03-01 00:05:00              NaN   \n",
       "2913951         2  2023-02-28 23:26:02   2023-02-28 23:37:10              NaN   \n",
       "2913952         2  2023-02-28 23:24:00   2023-02-28 23:38:00              NaN   \n",
       "2913953         2  2023-02-28 23:03:00   2023-02-28 23:10:00              NaN   \n",
       "2913954         2  2023-02-28 23:03:03   2023-02-28 23:12:51              NaN   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0                 0.30         1.0                  N           142   \n",
       "1                 0.00         1.0                  N            71   \n",
       "2                 0.00         1.0                  N            71   \n",
       "3                18.80         1.0                  N           132   \n",
       "4                 3.22         1.0                  N           161   \n",
       "...                ...         ...                ...           ...   \n",
       "2913950           4.65         NaN               None           249   \n",
       "2913951           2.47         NaN               None           186   \n",
       "2913952           3.49         NaN               None           158   \n",
       "2913953           2.13         NaN               None            79   \n",
       "2913954           2.28         NaN               None           161   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                 163             2         4.40   3.50      0.5        0.00   \n",
       "1                  71             4        -3.00  -1.00     -0.5        0.00   \n",
       "2                  71             4         3.00   1.00      0.5        0.00   \n",
       "3                  26             1        70.90   2.25      0.5        0.00   \n",
       "4                 145             1        17.00   1.00      0.5        3.30   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "2913950           140             0        20.22   0.00      0.5        4.84   \n",
       "2913951            79             0        13.66   0.00      0.5        2.65   \n",
       "2913952           143             0        17.64   0.00      0.5        0.00   \n",
       "2913953           162             0        13.56   0.00      0.5        2.63   \n",
       "2913954           140             0        14.89   0.00      0.5        3.78   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0                 0.0                    1.0          9.40   \n",
       "1                 0.0                   -1.0         -5.50   \n",
       "2                 0.0                    1.0          5.50   \n",
       "3                 0.0                    1.0         74.65   \n",
       "4                 0.0                    1.0         25.30   \n",
       "...               ...                    ...           ...   \n",
       "2913950           0.0                    1.0         29.06   \n",
       "2913951           0.0                    1.0         20.31   \n",
       "2913952           0.0                    1.0         21.64   \n",
       "2913953           0.0                    1.0         20.19   \n",
       "2913954           0.0                    1.0         22.67   \n",
       "\n",
       "         congestion_surcharge  Airport_fee  \n",
       "0                         2.5         0.00  \n",
       "1                         0.0         0.00  \n",
       "2                         0.0         0.00  \n",
       "3                         0.0         1.25  \n",
       "4                         2.5         0.00  \n",
       "...                       ...          ...  \n",
       "2913950                   NaN          NaN  \n",
       "2913951                   NaN          NaN  \n",
       "2913952                   NaN          NaN  \n",
       "2913953                   NaN          NaN  \n",
       "2913954                   NaN          NaN  \n",
       "\n",
       "[2913955 rows x 19 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\"\n",
    "df2 = pd.read_parquet(url)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2913955 entries, 0 to 2913954\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int32         \n",
      " 1   tpep_pickup_datetime   datetime64[us]\n",
      " 2   tpep_dropoff_datetime  datetime64[us]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           int32         \n",
      " 8   DOLocationID           int32         \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  Airport_fee            float64       \n",
      "dtypes: datetime64[us](2), float64(12), int32(3), int64(1), object(1)\n",
      "memory usage: 389.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = transform_dataframe(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2855558, 20)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 10.9 GiB for an array with shape (2855558, 514) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m dv \u001b[38;5;241m=\u001b[39m DictVectorizer(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m trains_dicts \u001b[38;5;241m=\u001b[39m df2[categorical]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m X_train2 \u001b[38;5;241m=\u001b[39m \u001b[43mdv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrains_dicts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m X_train2 \u001b[38;5;241m=\u001b[39m X_train2\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      6\u001b[0m pad_zero \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((X_train2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\kiramishima\\.conda\\envs\\data_engineer\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\kiramishima\\.conda\\envs\\data_engineer\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kiramishima\\.conda\\envs\\data_engineer\\Lib\\site-packages\\sklearn\\feature_extraction\\_dict_vectorizer.py:316\u001b[0m, in \u001b[0;36mDictVectorizer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    294\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Learn a list of feature name -> indices mappings and transform X.\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m    Like fit(X) followed by transform(X), but does not require\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;124;03m        Feature vectors; always 2-d.\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kiramishima\\.conda\\envs\\data_engineer\\Lib\\site-packages\\sklearn\\feature_extraction\\_dict_vectorizer.py:284\u001b[0m, in \u001b[0;36mDictVectorizer._transform\u001b[1;34m(self, X, fitting)\u001b[0m\n\u001b[0;32m    282\u001b[0m     result_matrix\u001b[38;5;241m.\u001b[39msort_indices()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     result_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mresult_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fitting:\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_ \u001b[38;5;241m=\u001b[39m feature_names\n",
      "File \u001b[1;32mc:\\Users\\kiramishima\\.conda\\envs\\data_engineer\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:1056\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1055\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1056\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kiramishima\\.conda\\envs\\data_engineer\\Lib\\site-packages\\scipy\\sparse\\_base.py:1287\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 10.9 GiB for an array with shape (2855558, 514) and data type float64"
     ]
    }
   ],
   "source": [
    "X_train2 = setup_features_ohe(df2, categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2855558, 514)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('yellow_trip_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 514 features, but LinearRegression is expecting 515 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kiramishima\\.conda\\envs\\data_engineer\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:286\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kiramishima\\.conda\\envs\\data_engineer\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:269\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    267\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 269\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[1;32mc:\\Users\\kiramishima\\.conda\\envs\\data_engineer\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\kiramishima\\.conda\\envs\\data_engineer\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 514 features, but LinearRegression is expecting 515 features as input."
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_engineer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
